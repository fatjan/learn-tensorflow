{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lab4-Using-Convolutions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvhexLzYmP2qRL6wEBD2W8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatjan/learn-tensorflow/blob/master/Lab4_Using_Convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn3WIabA0COT"
      },
      "source": [
        "# Improving Computer Vision Accuracy using Convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI7NKHR00Ejd"
      },
      "source": [
        "Previously in fashion mnist "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdczL7AszjHY",
        "outputId": "9c3fd4cc-509b-488c-f521-36b555522502"
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images / 255.0\n",
        "test_images=test_images / 255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4938 - accuracy: 0.8247\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3722 - accuracy: 0.8651\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3350 - accuracy: 0.8778\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3114 - accuracy: 0.8855\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2936 - accuracy: 0.8912\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubsMKrqw0SGj"
      },
      "source": [
        "Now we would like to add convolution and pooling to improve our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRZvzXOZ0WA2"
      },
      "source": [
        "First, the image data need to be converted by using reshape before normalization is done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4LVZsdL0mnN"
      },
      "source": [
        "Let's find out the length of training images n test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dx4AjEK0qvH",
        "outputId": "ea4acb04-5955-48c2-fd99-4284f73a8faa"
      },
      "source": [
        "print(len(training_images))\n",
        "print(len(test_images))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3iUa18e0atR"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images.reshape(60000, 28, 28,1)\n",
        "\n",
        "training_images = training_images / 255.0\n",
        "\n",
        "test_images = test_images.reshape(10000, 28,28,1)\n",
        "\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw7PfVPV1g2O"
      },
      "source": [
        "Now let's create a new improved model with convolution and pooling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehJZFnW_1l0e"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')      \n",
        "])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlOwyg2f2o46",
        "outputId": "5af6a85c-f05a-42a9-d052-8f56399aea69"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4389 - accuracy: 0.8403\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2940 - accuracy: 0.8907\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2481 - accuracy: 0.9069\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2167 - accuracy: 0.9179\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1901 - accuracy: 0.9286\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2518 - accuracy: 0.9113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgpLuVK93uBi"
      },
      "source": [
        "It is seen that the accuracy is improved by using convolutions and pooling on the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXIeGLSO5Sko"
      },
      "source": [
        "# Visualizing the Convolutions and Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlkvYaIF5XW8",
        "outputId": "e7192841-76a0-4005-d3fc-c545018e4e6e"
      },
      "source": [
        "print(test_labels[:100])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
            " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
            " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "qPbQKzdI5dUx",
        "outputId": "f32c3127-c273-4f0c-e277-d6ec99da216a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f, axarr = plt.subplots(3,4)\n",
        "FIRST_IMAGE=0\n",
        "SECOND_IMAGE=7\n",
        "THIRD_IMAGE=26\n",
        "CONVOLUTION_NUMBER = 1\n",
        "from tensorflow.keras import models\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
        "for x in range(0,4):\n",
        "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[0,x].grid(False)\n",
        "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[1,x].grid(False)\n",
        "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[2,x].grid(False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD7CAYAAAC2a1UBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9eXQlV3Wo/+2quoN0JXW31PPgbnd7bM/YDAaHGAijSZxhheC8l5AXgklI3oOVrBCH9fKSl6y8OI+X/EISICGJgQwYCODYATMYsDHGYDzQdru73YPbPajVrXm8c9XZvz+qpJZUV9KVdKV71TrfWlr31r6n6uw6unefU/ucs7eoKhaLxWJpLJx6K2CxWCyWONY4WywWSwNijbPFYrE0INY4WywWSwNijbPFYrE0INY4WywWSwOyKOMsIm8RkcMickxE7qqVUhaLxbLaWbBxFhEX+CjwVmAvcIeI7K2VYhbb+VksqxlvEee+AjimqscBROSzwO3AwZlOEJHVvuOlT1U3VFNwUuf3RqATeFJEHlDViu1r27b6toWw4wM+ArjAP6rq3XOUX9Xtq6qyVNde7W3LDN/dxRjnbcDpScedwCvnPs1dRJUrneDkPArPu/OzbVsd8+34zrNa2zdYhjpWa9vCTN/dJZ8QFJE7ReQpEXlqqeu6wKjU+W2rky4XGhMdn6qWgPGOz2JpGBZjnM8AOyYdb49kU1DVT6jqTap60yLqslTAdnwLpqqOz7bvwrBzJbVhMcb5SeBSEblYRJLAO4EHaqOWhSo6P9vxLS22feePXShQOxZsnFXVB34L+DpwCPi8qh6olWIW2/ktIVU99VkWhHUZ1YjFTAiiqg8CD9ZIF8skVNUXkfHOzwXusZ1fzZjo+AiN8juBX6yvShcMC1woYJnOooyzZWmxnd/SYDu++iMidwJ31luPRsYaZ8uqxHZ8S0bVCwWAT4Bd5zwTNraGxWKpJXaupEbYkbPFYqkZ1mVUO6xxtlgsNcW6jGqDdWtYLBZLA2KNs8VisTQg1q1RQ5pTu9juXUNR8nTmniQww3Q038AVej0uDo/mP1FvFS0WywrBGucaste5hZ/f1Exf0eOTOkhfdh+vT9zMnVecJen6/Pjj9dZw6bky8zMx2aHsfTHZX17ynpjst4/9Q0z26at+OSa7cceJmOzqrz1cpYYWy8pglRpnF0FQlNnCITqSwXHSGFPAaHb264mLi8N42FtVA0DaFdrSOZIJv4b6WyyWC51VaZxTiU20JrdQCsYYLb5EGAJgKiJJrk/fzpXpdRwpjPB04UsVDbTg0ZK+mCZ3HV3SyT09GfKSZahwHIChUsCpwQ481yz5fVkslguHVWichZTbygYuYtjtY5TKMdpFUlycWMuNHSW0v5UflZKYoMLoWTxa3I2sZSNng6Oczh8Axjc8CTkT0F9M4znWOFsslupZhcZZKfjDdDvHKQZjoKG7wXFaSbitBCaPHwzhOmlu7Ai47coD3DTQzmt6f5aBUoIfDQiny2PsSLRw5RooGeGZwTJd0jepDsF12nCdJs4xwCPdm3BlybL8WCyWC5BVaJyh5Hcz4PcChnCUK2SSm+nwdjNqehjIHyDhZnjTruPs/J9j7Gh2uH5dG8nuZzn5R0kePXo5r730WXa/+xB6cpQ/+X/v4QsD568vkqA1tYMmZw2nguc4NHKuTne69HzssndPOf5OdypWJtV8R0z2P47cEpO950RPTPYL1zTFZP/z5Kr82lpWGavoW+6S8NpxJEHZH478xy6O04wjSVJuG0lN4koCAKM+fWNtuAcexl2bwdmRxe3pYix7DVnfY3Qsg54ZodS9lqIJR8Wek8J12hAJmzWgTNnkMWasXjdtsVhWKKvGODclt/Hm1G10pBy+mz/FkeyXSXjtXJG8lRZtpmjKlKWMJynAoVju4YMHPPb+9p20p4SLmn3KKvygD06YXr5wZgdbnnkvRqGrnMUTjy3sZmv6EgqSo9Pfz2jxNIrBkWYAjI7UtxEsFsuKYU7jLCL3AG8HelT16kjWDnwO2AWcAN6hqoNLp+biafLWcWmbsK2pxOHsBo4ACTfDFtaxLunRUyoxSBZHwizAqiWey32O53KQ9DazfewGALr9IxTKfRgtovkCImm2NL+cDt1MizazxkkzbNKcNCUCM4xIEkeiR3MbGNFSA9Znbqwof1Oyckz7zwx+bCnVsSwR1YycPwX8LfDPk2R3Ad9S1bujBI53Ab9Xe/UWz5bMa7iBqxERjowoB4ddXnQOAkrCaWZTOsHaJHSWAk7zAvnyIKrlKdfwTZbe4BiCQ9EfwGge1Wh9tPoM+acpuCMknCbS0kLBGaMcjIYfa4AhvyDdReQEMEq4GNu3uewsltXDnMZZVR8VkV3TxLcDt0bvPw08QkMaZ5eb3Wv51Uv7eHFkDX/edZizuScmDGvCaWJLk9KeDPj+cJn+3HOcnyQ8jzGjjBbG/cZTP1N8csWT5ICpoUqCidcJQ74wXqeqfXMXW3ret+k3Y7KrN0xdivjugz8VK5Py4gkvPOfe2ilmsVyALNTnvElVz0bvzwGbZipYn3Q0Lp7bhudmMApnsy30FBLkTDgqbm++ll16FR3aQj4QzhU8RpxhZtstOLtPYvyzRRlhi8XSQBSeuHbe56Rf+VzN6l/0hKCq6mxpZuqRjsZz27gh+XY2uxnO+ln+tLObnA4yUngJR5r539teznve86+ceux63vvQ1TwnTzNcPLUcqs0XBb4RtdvfR205gc3DZrFcuCzUOHeLyBZVPSsiW4D4AtW6IXhuhs1uhi1NLieyeU6MfZNwVOviuWu5buM5Sr/xQXaU/4K+b+6gP/ejeis9E7eo6hkR2Qg8JCIvqOqj4x/aPGwWy4XLQo3zA8C7gLuj1/trptEiWNt0NVdyIw4OZ4IRTmTLnNIDgCGT2sPtzW9mezMcGcjhv/FZftT7Xzilj9Vb7RlR1TPRa4+I3Ae8Anh09rMs1bCSJ1s7v12uKE+/sv6rMkRkB+HigU2ET36fUNWP1FerlUk1S+nuJZz8Wy8incAfEhrlz4vIu4GTwDuWUslq2c21/OTmNP1Fl38ZPkBP9mnGJ/i2eFfwvqtOsnvXCf7i2z/Orx+5n8DkUS3WW+2KiEgGcFR1NHr/JuCPl6v+21t/Iya7vC3eVlffsH/Kccr78pLptAQ0zGTrBYQP/I6qPiMircDTIvKQqh6st2IrjWpWa8T33oa8oca6LJDzcSyMKGdyHkMlKAThBF/C20BrcisbzHpODQUExx06s+AHQzT4wuNNwH0SxuTwgM+o6tfqq5LFMjvRQoGz0ftRETkEbAOscZ4nK36HoCPNXNx0C5vMRnqlj38b2U/JjJEvdQHCdYk389aOVobLDh95cZRut0R36cs0uGFGVY8D19VbjwuYWSdbwU64LpZoCe4NwBMVPrNtOwcr3jgjDi3axhonyRkpMZQ/BAThzjynhfVOhosyBU5k0xzmGYbGnq+3xpbGYNbJVrATrotBRFqALwIfUI3HLbBtOzcr3jiryXPcPEO3u56h0mnA0JS8iHe0/CQXtwaczrr8+ymlT4cZK52d83oXOr+47n0xWaXtvfePfjwmu+eXdsVk7X9bOR52o2MnW5cOEUkQGuZ/U9Uv1VuflcrKN874jBQOM8LhCdm6xE5++dIzXH3VIf72odfzyf5/w2iORndlWJaHek+2VotvPl1R7jnvWmZNqkfCSZJ/Ag6p6l/WW5+VTIMa5zDHn+etI+FmKPmj+MEAcxnXhLeBdamL2Wp2cngwRfD8Vbw4JtGKDGuYLRPYydal4zXALwH7RWRfJPuQqj5YR51WJA1onF1cpwXPzXBJ4mZ2yHpe8s5xJPd1VAuznnlZ8rXctnYT+UD4x9ODnDnTxXD5hyg2uarlPHaydelQ1ccAm/anBjSccRYEEQdHPJq0idaES1O5uapzm7SJ9mRAf8nlpByiP9uwO/8sFssieFd7PAjXXPxT3yvmVb7e7qOGM85KQGCyGFPiiPMkZ/z1jJmeWBjPShzRJ/n8uRvJOtlGjZWxZDRLO1ekb5si21f8z1i5xcT27fjYiQWfa7FY5kfDGWdQVEsopdhE31yMFA7zzDzKWywWS6NSF+PsSAbPbcVokSAYRQmwE3aWC52ZHsX/7G2PVJS3pv9gCbWxNDp1MM5CS2o7W9wryMow3YUD+MFo5Law8ZAtFosF6jRy9pw0GZMhcHwcSSCSQHDDEbT6y7y6wo1e4xlQQmQGucVisSwd9THOkiKlCZq0mbS3FtdJstm7kk1mI2fdc5zMfmfOZXO1wJEMbemL8ZwUQ4UT+EF/7HPHSWO0hDFjNLKRdnBoo2mK7N0dvxwr9w+9H43Jrmn++ZgsremY7Mn8v8ypx7XNvxCTPZf7XEzWnNoVk+WKJ+a8vsWyWnDmLlJ7BIcEHglNhElR3TXsNNu4uqWFPeYiXKdp7ovUAMdJs97ZySbdRcpbG9fSSZP0WnGduKGyWCyWpaQuI+cxv5dTiU5KmiPn96NqOJk4Q3lsC+ecbowpzXBmGB7UczPhkYR9S2CKqBqMKWA0W7UexhQY0E48SVEKpsdmUYyWKAdZArP0o3iLxWKZTDXB9itmNhCRduBzwC7gBPAOVR2cu0olWzxBrnQ6PIoyU79UPscJEihlVCsbZ8FlbXo3HbIdFw9PPQyGrDNGSXMM+afJFauPoWE0y2DuQKRVfDLSmLHInUHV17RYZuLTA3GXEsCn/3WZFbGsCKpxa4xnNtgLvAr4TRHZC9wFfEtVLwW+FR3PWZ0jGQQJ1zJriXCFRoBqCaPZGQ3zdAxm4n0lw1otyvgEZCXjq5P+LBaLZfmoJhPKTJkNbidMXwXwaeAR4Pdmu1azrGNv+u0c5RmG8/NPjKAEDBWOM+qcRcRBxAndGVpG1RCYLCvNkIrIPcDbgR5VvTqSzfupJOk4bE2npsgqTf5VYn/u3+er9oxUmvyrxNA3EjFZ8sdrpobFsuKZ14TgtMwGmyLDDXCO0O0xK2nHZU+yjbXu1nmqOY4SmGFK/jmK5S4KpU6K5S7Kfi9+0L8sKzyWgE8Bb5kmW8BTicViuZCoekJwemaDKNwiAKqqM2UzmJyOJiHNHCz3MmhOL07rZWZr5sf46ZZrMQr3Z/dxNvu9ml1bVR+NOr3JzPupxGJZTczkv5/1HGf+59STqozzDJkNukVki6qeFZEtQE+lc6emo3H0+fz9E5OAK4U3pK7l/73vX9DAZeRv7uAzNTTOM1DVU8nkjq/ZaV1qnSwWyzIyp1tjlswGDwDjMfXeBdw/d3U6aRJw5VAKlELvOgo96ygEy+vTVtUZZyRV9ROqepOq3pSW5VkbbrFYlgcJf/uzFBC5BfgusB8mlkh8iNDv/HngIuAk4aTVwBzX0vPbpVcOa5r2crPzYwB833x3QZOZIcHTqnrTdGnk1vjypAnBw8Ctk55KHlHVy2e78kpt29pRuW1rxepu3wBVXbIA+qu7bWGm7241qzVmy2zwhsWqtRIYzh/kayzUIC+I8aeSu6n6qcRiaRxExAWeAs6o6tvrrc9KpC7bty3nEZF7ge8Dl4tIp4i8m9Aov1FEjgI/ER1bLCuJ9wOH6q3ESqYBg+2vLlT1jhk+WhVPJZYLDxHZDtwG/Cnw23VWZ8ViR86WCxYRuUdEekTk+UmydhF5SESORq/r6qnjBcpfAR+ESdt4pyEid4rIUyLy1PKptbKwxtlyIfMp7AafZUVExne7Pj1buckrjZZJtRWHNc6WCxZVfRSYvoLodsKNPUSvP72sSl34vAb4KRE5AXwWeL2I2NBOC8AaZ8tqo+qwA/bRe/6o6u+r6nZV3QW8E/i2qv7XOqu1IrETgpZVy2xhB6LPJ+1unbmcxbIU2JGzZbXRHW3sYbawA5bFo6qP2DXOC2e5R859EGTD1xXNehZ2Dztrrcgk+iA4Gb1fqH6NxHzvodq2XegGn/H2vRDatlrG73Upv7cw9btbqf56sVz1V2zfObdv1xoReWqlz9A2+j00un7VUIt7iDb43Er4I+sG/hD4D+YZdqDWeq0U6n2vq71+63O2XLDYDT6WlYz1OVssFksDUg/j/Ik61FlrGv0eGl2/amjUe2hUvZaCet/rqq5/2X3OFovFYpkb69awWCyWBsQaZ4vFYmlAltU4i8hbROSwiBwTkRURcEZEdojIwyJyUEQOiMj7I3nDRTdbie0LKyd63Ept37mod/vP1a4ikhKRz0WfP1EhIfJi6q74+55W5lYRGRaRfdHf/6pV/bOiqsvyR5iH5kVgN5AEngX2Llf9i9B7C/Cy6H0rcATYC/xf4K5Ifhfw53XWc0W2b6T7a4GXAc9Pktn2XQXtX027Au8D/i56/07gczWsv+Lve1qZWwnTyC3r/2U5R86vAI6p6nENs7x+ljBCWEOjqmdV9Zno/ShhdodtNF50sxXZvrBioset2Padizq3fzXtOlmXLwBviBJPL5pZft91Z1HGeZ6PeduA05OOO2mQRqiW6HHqBsLktlVHN1smVnz7TsO2b31Zrvavpl0nyqiqDwwDHbVWZNrvezo3i8izIvJVEbmq1nVXYsHGOUrg+FHgrYSP+XeIyN5aKdZoiEgL8EXgA6o6MvkzDZ99ar4m8UL1cc6XpWpfS3Wshvaf7fcNPAPsVNXrgL8hDAGw9DpFPpX5nyhyM/BHqvrm6Pj3AVT1z2Yp//gC9VxiHNa562lLGHK+Q18wiKpPwmkhpSlKUqJkRqnB97NPVTdUUzDq/I4AbyQcTTwJ3KGqFdOALyakpec0V7piTHLNhlJM9qPu8pTjZokPaDak4tfqL8ZrHNNFxZipum0h7PiAjxD6PP9RVWdNoruUIUNvvPHiivKnn35pqapcCEdU9fJaX3Q57cJM7TwTy9j+Fb+7i4mtUelx5JXTC4nIncCd5yXuIqqci3Ej4BDaNgfVMhDMeo4jzbwu8w7etKXIvsEmPjl4H6VyD5ubX8XOYBed7hlOZh8mdIkthoqRt2ZiwhcHICLjvriKxjlkYW27tunqCldKxGTf+eX4l7Xtw91Tjvem4xEi37cr/jW750T8oe2x/D2z6jk71bftpKe+iY5PRB6YqeM7z9J8d5948k8qyj3nXUtS3/wJoProffPlyfBlKe1CyEztPBPL1/6Vv7tLHvhIaxCwXCSJ564BwA+GpxlJwXPb8dwmUm4bGaeD9bqVW9vWsynt8/Vun0fzn6KSgRZJ05raSdJt4ajfx+CpNXQ5nZT94bAuLVKgREAZR5owEBn7ZXnCq6rzsyyIBXR8q55ZnywWiqr6NZrbu+BYjHE+A+yYdLw9ktUcR5poTW4FYLhQIphknAWXpkQ7zW4H63UbW7WDizMJ3nvDc2y95CT+A2/ju6dcVOPG2XUybHGvoEmbOW6eYX/hSPSJAi5lCuQlT6BlXKcJDBg1KP5S3Oa8iT+VWKpkgU99qxedX1jVebmMLJVZjHF+ErhURC4mNMrvBH5xsQo5kqE1vRPBYbR4msAMo+pTNjkAwsnaSYiDKymS0kyRAt06TDK/jmdOXUzf8Fo6cy4Jtx0/GMVojsmjXlWfEfooOE0Uy3GfcjEYYdjrJ9AyzYn1BFokW+yKdBAkehRbImM9Z+dXi6cSy8zY9p0/C3cZWaazYOMcPY78FvB1wh7yHlU9sFiF1jVdxk82vZqkAw+6B+gcewTVIvlyX1Tv9JkkhyZnDS26hn7OcKL4A16QBD94aQspaQGG2Ji+grwZZiB/CNXCxJmBGeFc7mkEFzNJHn3KWOElstJFa3onl3EjKsqBxKPkS1lEErhOa1gyGF4KA70knd/dF783JvsfX34hJnvlyzfGZG0f/kFM9rvb3jfl+MNnPhYr89+P74nJftz7iZgsndwek31k9xtjsve+8MmYbJ4s21PfKsS6jGrEonzOqvog8GCNdAEgKc20J5W0C+lcBgCRFCmvHSWgYErx0XNEyeTwgwFA6ffPAZBJ7WG7dzU4IJKYYpxBUS3M6EFWfFR9jJZJSQJFcWR8osyZeG+cJtAyqF8zI71UnZ8FWKKOb6E0zsRfTbAuoxrRcJlQ8maYMzlIukKWIQBenv45/mBvHqPCnxxK8WT+XybKq5bpL77IsHuGkj/MVNeE0J7YyVXOVvrK6+lxXoiWxMURSeM6GYyWMGZsynWypXM8n/phqF+5Z6LecjBE0mvnlamfZUuimeeDTo5kH2T21SHVsxSdn8V2fI2AdRnNTcMZ57LJ01MqkRCHImMA3NTWypt/9wtgDF9+/7t5Mj/5jICSf47SDAPWdWYDu1qFdCGFZ9IzlnOdDClvLeUgS8nkmGxgjRllKP/8tDMCVANEHG5oa+HatXlM13aOSuXJR0tjYTu+JcO6jGpEAxlnFxEXo2XOOf0kNMl6uYjWlg24Aj3/uYdy2aMzN926ujQlt5Fy2/CcFGlppaCjDOSPYMwYrdrMxnRA0Xh4+RQAgodICiWIfNgOHelLuchcSm+ih1O5xzEmB5hJ9VTu3ANTpLegnM6lGPBLoKZiOYtlldBQLqOVTMMYZ9dpIeG1EpgSR/LfxnMz3NZ0Ozd1GIZKyl1ffS1DpYDHzWOx8651b+WiZAvrksKmtKG74PB5U2Qof4hNiTTXtPfS5K0lPbaGEcDz1tGc2EApGKNQ6gLxuEmu5/VbDQeHL+Gz5WPkS+dQAsDALMvngiDHs/5puvs2csw5gjbQLtf3bfrNmOwD741v9Hj1TT8Tk70iE48Qeee2X4vJbtg0df38PYM3xMr8xa5rY7L/dujTMdnHL4v/hj9+Kh+TWRoX6zKqHQ1inAXXaSLtrqXICCW/F4C1SYeLMmPk/RaO5bP0On3kylO3+Io4JPBIOhJOIrqGlOvgSLjMLVAoGQ/fOJhJrgrBQeT8LjVPhKRjcAUcmbx7zWHyCFokHU0sFlEtoQSMMkBCkuTMIFNH2xbL6sO6jGpDgxhnhy3pq7nM7KbL6+dQuR/HSXL12hKvvWo//v7r+OTgSfpKxygHQ1PODIJRntPv8WJpPclyE82jreRklJHiKSDge+aH9L9wHcMyyFDxOBDuMhyNVn0oAajyWPADTp65gn7nONnSuWlL60KD60iGG9M/y6XpVp4v9rM/fx+qZfqKRxhyTleYkLRY6s+uljfHZCfGvl4HTSzzoSGMsyBsDLawpzWBjHVw2EniOikuyoyx8YbDbHpxD4Pl0xRKnbFzFZ+RwmFGOFzx2n3Zp3mMp6eeo1N3GUJAf+5H9POjWfV0nDTXZNp4RUce093B84UUqqOU/V7Ks55psVjqzXIsWazUEc7FibHKDxkNYZwByuJTCKCkAaoGP8jyne52Ml94G0/0bqA9sRNHHLLFLoxm66Kj0RKHszkC08yx4nCFDTEWi8VSGxrGOOclx2h5HVlKKIYgGOHv+j7PPYNttCd2ckmwm0Au5unkI2SLL9ZFR2PG+H7h8zxRSmNMoQZR6paWc/m4/zt9V3yC7adb18Rknxr415gs6BuLyX62e+o+Ak/6Y2V+5WB88u+Wpl+NyX798GKi0lksFxYNY5wDfHxVgolJOw3dBX4vjjgEEsZiDSfrhGp9u+eXzZUnRZQTzucZqGZNsiDjuwE1hwnqM3K3WCyrh4YwzoqSZYg+fyNDzmBkRM+TLXbxdPIRHHEo+EM40hwZ23DkKpIEnGj79HnjDtCa3sMu53pGnCFO535AYIbx3LWkvHZ8k6dY7mYuA+257WxuugaAc/n9+EF8dGixNCp28m9l0hDGGaCkOUYlR4H4o7PRbOTKCAPjO04SY0ApMT4KdiQVrqmYyOwSAEKbt4WLpZ1+P0OX0xQZ5wwt3gYKZoSS3zfnjr6k18rmIAzK0+8et8bZYrEsOQ1inA1Zv5euhEPeH4IZAhuFY+xyaJgnJuMU1I8Wu5kwA4oaNHJ9jAY9nJQtjDhDBCb0txrj42sRo+VoR5+wpulKNjl7GKKb3ty+Kf7kkj/M6fQxAMqlyrE5LBaLpZY0iHFWCqUzFEpnCdcUz+xPDjd+TJ2IU3xQP/QvO02AQTWM/zxaPM2RRI7AlDAm9BUbLeNrEd+EBl4kwXXczKvXpXhheDtfdl6cMjr2gyG6s1E2nRW0yWRtMp4K6o92/npcdvLjVV3PdeITh1/JT81elHJbY2X+d4U6//Dk38Vkr2n6bzHZ9/KLDg9qsaxIGsQ4h2FBXacJY0oTQfEdpxXPyRCYPIEZYSEbPMLocdlow8n4+QbfFAlMCY3G2GV8cn6akom2bE+9CuN+aZEkQrRDsEEyolgslguPBjHOLtsyr+KSYA9nnT6O5r6JUubq9NvYm+zgWHGEZwr3zbm+WdEwrvIk46paxPfHDXNoYP1gJHJxGMLocoYfBd/ixdGt5INBgmCGsKJ4tDddxTrZSp85yVD+ELUKD2qxWCyTiT/3TkNE7hGRHhF5fpKsXUQeEpGj0Ws8Ss48EIR2s4ldzWm2mPWIeAgJdjjruHKNYbvXiki1/YiZFhlOoxHuZCMahEH2J/zKSqHUSU/2h4wWjs48IhaHVmcjm80mWtz1CDYxpcViWRrmNM7Ap4C3TJPdBXxLVS8FvhUdLxhFOcMRnsn3ccQ5gtEijpPk0laXV2/u5oo1YWCkuTGoBtEoebExLoSkt5k1TXtJJbYSBmfK8DJnN2/cmORavRyR1JQzWtOXcm3zL3BZ5ifx3I5F1g8ickJE9ovIPhF5atEXtFgsK4Y5h6Oq+qiI7Jomvh24NXr/aeAR4PcWrkZAf24fA+yfcD+4TjvXrs3y8pt/yMC3b8XrnTlQ/iRtqZWbQXDpSO1hu9nN2dRpzvh9eG6Gm9cHvHHPUXxzBd8oJKdsSLnYeRm3d7QzUFrPvXqKgVxNlty9TlX75i4W556+j8Zko++O5wY8+ol4aNF7h/85Jvvw7nfEZB986UtTjvMajzLyF90Px2Q3N8XjHPzD647GZF95IZ7J6HePfyIms1guNBbqc96kqmej9+eATTMVrD5XmE5xJxgtczafouvIxXRmM5go47XjtOA6aQJTmBQQPxwlO04r6UQHgSlRKvdMup5M1DH1eKpsPJt2eOgRUCYnOUqaAzUY49NT9OgcWE9v0UGnBdYvSI6B0nqGSsoNLv0AACAASURBVOCb6QljLRbLhU4tN/wsekJQVXW2HGALzRXm+4P8de+zfPHh3ZxzDlEs9yCSYnfTa9lhtnDaOcuJwuMEJh+teVYuan41b0hfwkhZ+VrxIUYLR88vr1MzsQpEJIEjTVHy1lDmOm14bmZKjOeh4ikGeYnAFFACyn4f9wx+n/uHttNjvkNgpm6YOV54nHv1FL4pMFqcGoR+gSjwjajd/j5qywlskkyL5cJloca5W0S2qOpZEdkC9NRSKQjXLndnf0A3P5iQOZKhw3SwJZ1krNDOSfEQXBQHCGgPOtjT6tNfdEmWW8KTxMORZLQWOiwHzsQuw/GBs+MkJ9boKgajhpIZxkxKCKv4s4YW9YP+WrkyxrlFVc+IyEbgIRF5QVUfndDHJsm0WC5YqpkQrMQDwLjT8F3A/bOUrQrPXUdT8iIS3gaYYRWEapFjsp+nSqc5Ls8TBLlo1By6F8pSZqzskvWFIPJ9tqV3szf1E+xsejWuExls9fGDUYzmCa2zy6b0VbxMbmGHczW+KVL0B1ATj+AmksZxWqN4HkuLqp6JXnuA+4BXLHmlqwQ72bo0iMgOEXlYRA6KyAEReX+9dVqpzDlyFpF7CSf/1otIJ/CHwN3A50Xk3cBJID5TNC+EpsR62r2djJpeBoPhiuE4w5HrPvrZNyGZTF5yDJeF0XLoswZhk7OHlzetp6/YTpe3n6A0PLGj8Pw9uuwKdnPjuhTHRjdyuJjFDwYr6uk6GRJuhnIwih+MR7mrPSKSARxVHY3evwn44/lco1Lg75v+Nh2THc7GJw4rcSob75DuXP/OKccf645f63c2/3xMdnfnx2KyG795UUxW8vdXpdsCWfBkq2VGfOB3VPUZEWkFnhaRh1T1YL0VW2lUs1rjjhk+ekPt1HDwTZG8jlA2uYl1yiLJMNynltGJtFEzG8MsQ5zJGUYDn3I06s3JKD2FgIGgSGBmCI6vhmEZ5Vy+iT4/j84Y2wNU/XAruPoz6DJ98nHBbALuExEI/0+fUdWvLfaiFstSEi0UOBu9HxWRQ8A2wBrneVL3HYKCB+JQKPdQLPeHoUDxAZeW1E7WeNsY8c8yUjjGXMvkunP7+HriNEZ9SuUeQOnKPU2fd4zAFCn7AxXPU3wOFb/Ji8EaykE2NtE3uWRgxjAmOyk06WRcHEmjBBOTlAtFVY8D1y34Apa5mHWyFeyE62KJluDeADxR4TPbtnNQZ+MsEE3qGS2gFCZ9IiScZpq1lbwzjCBhmHxJh+FBNR9zfRjNki9N3eJtzCiFKiLJ+cHgDK6M6QSTTO7UUbIgIA6iNs3rCmDWyVawE66LQURagC8CH1DVkemf27adm7oaZ8dpYX3TlXik6CsepeSfQ/Bw3XC7tm8KDLhd5INBFCWV2MqHtv4UP3HRKf7j+C7+v3P3VmlQa4/rrKEltQ3VgLFiJ0aj0fTEJGL9v297TNyH+6R5NCbzTTyNlOf8Skz2193xjSmJClHopnPf4JmYbGvmx2Kyjbo9JttXunfO6y+EyZOtIjI+2RpvHMu8kTBt0BeBf1PVL81V3lKZha7WqAmek+EicxmXmMtoTqwPheKR9NbQ5LXja5GxcjclfxgwrElu57fe+g1e9u238xuv+iEpr73CVYWZVnvUkqS3hu1yJZvdy3Dd5kgabqSx0eoaGxHJRJNVTJpsfX72syzVIOEkyT8Bh1T1L+utz0qmrsbZaJEBp59eZ4DShJ/X4AcFSiaLHxQITDGafINCMMyz+67B+ej72ffiJfixpW7juQGdKTLBg8m7/yogksZ11uBIhnHjLpKctGxuqsEPTIlhp59RBjCmsRO9WmJsAh4TkWeBHwJfsZOtNeM1wC8Br4+WKe4TkbfVW6mVSF3dGn4wwon8YwATa4pVS5T83sjHfD7+MiijxZd41/Pb2Pr7d3DaeSma9Bsn2n4dRa8Lt1ZrFCc6E62yGKPypKLQnNxGe2Ino0EPw/kXUALSic1kEhvI+f3ki53RJGCoU8nvpSs7Omnyz7JSsJOtS4eqPsZyPLquAuo8IRhE8TFgeoD70DBPzYqiWqJz7FE6xYuSuU5zH4gTZslWMylihosjiTnzl3hOiibNUHSaQRxQxZEECdK4kohkU8OOzhVf2mKxLBULsf/1nweaD3WeEGxlQ9NVJKWZnuILFMtdeG4HW5quw8HhbOF5Sv65KecoQZTENZ6txJEmmpMb8U2RQrkcpbQqR/E3/ArnnKcUjDHs9FIIhqN11gH5ck+0tC4fZQRfWf/cX9sT3+H4hVvjMs+JR4irxKama2Oyc7knK5ScVsbEo8194drLY7K/PhBPg7UvJqFiOFY/qHkEAYulrtTVOCfcVnaZy2gmSTbRT7HcRcpbyyXBbhLiMJrsZWCacZ4tLKjrNNHsduA7xWjNdAnVAEM+MrgzG1ff5MNs3CY74U4xZpSSsQldLRbL8lNX45x0M2zxMrQmHI6VOhgA2rzN3NCWJOnC8cHtDPBs1dcLTJ5c0E+gZZTxuMIGdLL/uhKKMSWKwQh+MJ6+apKe3ma2p24AoLP4I0r+ORzJkE5uwKhPsdxTYbv5+ATk7J2CZTUx06O4/X5Y4tTVODe7HVzfrnQkixzp3M5pYJe5hDsuP0ZzU55Dj13NsXlcLzAjjBXGR77jo2uN+6ZnODcojVHJmO5J3cyvb+1AVfj42SSH/ftpSW3nGnk1JXz28zCFUuekMwRH0oh4FTfLWCwWy1zUffu2UcEAZpJBFFEWtmmoOkM807kzuUsSmqTZDTCAp16ko0sCB/CQSisSxQljQ9tBkcViWQCiunzWI9ymeX69sed2sCd9CylN85J5htHCUVrTl/Jj7utJOA7fMz+kL/v0suk3E82pXex1bsFgOBQ8Rr50amKHoNEy2WJXhZUbbrQc8PzyOwieVtWblkLH6W0LsDvz1li549mvVnW9P98dD3tww/p4ALfDg1M3Av3Rmfj/673tN8dknhP/3v3xqY9XpVtllq5toXL7LuAqM8gbvQcPUNUlWx63sLa9kFZrVP7u1nmdcz+Hs1NDQY8WjvIg8dn9epIrnuApTkyRBWaY4fzwLGcFDftVsFgsjU+d3RountsW+mZNCVU/jEo3Dx+tSJL2pqtodTbSpM00mSbGnFGOFx7HD/ppTu1is3clAIGUCfAZ9s+QK/VgtDixgaQ5tZP2xC6MBvgUCbTMcPEEfjCI53awIX0FAL2Fg3WL52GxWFYP1QTb3wH8M+GWVwU+oaofEZF24HPALuAE8A5VnZfVcpxm2tOXkpRmcmaQYjBGOchS8nupNou2567hVu9mrlijdKR8NqfznM5t4a+6r+Bs9nGucn6M29ZnAMj6DsVA2De8h+dST1AMRiiUugC4xnktr2hppWwg60POV74jDn3Zp9mQvoK3N1+PUfgyAd3ZH8ymksUyA/ZZylI91cTWGM9ssBd4FfCbIrIXuAv4lqpeCnwrOp43gjPxd142/+BFqoKqYAhfJ2NUMFW4zIye/5u89C4pTXSklI6UkpTmWa4wf0TkHhHpEZHnJ8naReQhETkava6raaUWi6XhqSYTykyZDW4nTF8F8GngEeD35lO5apGRcheek6LgDxEEORAHxwlHumFQ+9lXX/jBMA/73+OpoQ2ktIlmbWFMOuktHASUA+a79A6Eu9ECyqG7wnSRL/eEGVaiEfp+8yinx3agGMoUMOozXDgBwDqzgSvashgV1g52cHo+Nzk3nwL+lvDpZJzxju9uEbkrOp5X2wKMEU82m0psjclO/VI87Oeme2Kx5+H4fDUI+T+5eELcH7z2LTHZH59a2PUtlguRefmcp2U22BQZboBzhG6PeaEahLn4TB4/yhsoJPHccAWA0eKUXH+Vr1FiIPcslXOchJN5J4on5tQlVzxBboZyTZpkQ1MWRUhrPAffYlDVR6N2ncyiOz6LxbKyqdo4T89sEOW2A0BVdaZsBrOloxFx8dwMjngEphBOBKpBCcIIc9FOvbVNV/Ma9xYAHgseZTi/vOnITjrH+UrntRiFTqdStIeas+iOz2K5sLnw/fdVGecZMht0i8gWVT0rIluAipFnZktHIyRIuW14kqLkj05smlY16KQt1DfKzfzvl7+IqvC7T9zMI8ucK/Js9vv8ff45IHS1LCcL7fgsFsvKZs4JwVkyGzwAjIczexdw//Rz50IJMBr6gcdHyYqejyAXZeEO1FAoJ8mXk/ixHlNwJIPrrImC4s8km3xPyVhg/fDVpdJEpOITmGECM7xcWU66ow6PuTo+Vb1pKTdfWCyW+lDNyHk8s8F+ERl/pv8QcDfweRF5N3ASeMd8K1ctki12TbwPCQjM2KTddfC8s4+/2f9KDHBIvj/lGo40c1HmFjYEGznpHKYn+zSu08IlTbey3rRz2HmOvuwznH8MEjqar+Fis5dBZ4Dj+UcxZhTXaSPhteIHefxggDo/No13fHezwI4PwCURkxXLXTHZaz53W0z2c21viMlSFTZxfWbwY9POe1+szHeCWPJl3vJkZ0z282vi5/778MdiMkvjIyIu8BRwRlXfXm99ViLVrNaYLbNB/Bc8L3SGgPVTd9cNF0/xuISxfkdKU3/UIh4bgo1clGhlONhED+A4SbaY9WxOpegub2b6puM2NrIj0UKy7HFCPAyC6zSRctsA8AOHatdZLxYRuZdw8m+9iHQCf0gNOj6Lpc68HzgEtNVbkZVK3QMfjeNIBtdtxpgSgRlhppGrajxgvhPL71fglNPFSHEdAxIfoQ3rOU6VO+hze6fk/3MlgSMeIu5EmisAwcNxMoh4tCS30OSsCXcZFk/OqGe1qOodM3y0yI7PYqkPIrIduA34U+C366zOiqVBjLOQSnTQmthMPhiMwn5O9e3qnImmzmNMjtPFp+hyUlHm7skGVBkpdXI0UaRUGptwpziOhyMeriQQEoRx8sKgRSIpmpMbSbltXG6uZYOT5rC3kRdKXTYcqMUS56+ADwLxBfSWqqlr9u3zODR7HWzSnbS6myeStE7GxcPFC8Nwxs4WHKFy6M4KGFOiFIzhm/zETsDAFCmbPL4phklbJxl0x0mScttokjWU8BkNfPKSm5iwtDQmdvfl8iMibwd6VHXWcJIicqeIPCUiTy2TaiuOhhg5i7hcqTdwc3uaIyPr+YpzED8oTHzuOilaTOhzdiQx7VyHBB5pV0iWk9HWb0i6baTcFozxY6mmAjNGoTyeuir0Lfv+ICPBKGBi+QKT3hr2mKtwEI47hxkud+IH2YkJy0blQ1uvjMn++9HvxWQdJp6TrzUdn2b4amHu8K1fHKluAu/21t+IyZZg8u9TLNHuS8uMvAb4KRF5G5AG2kTkX1X1v04uNNsSW0tIw4yc17lJtjSV6Ug5cQOMM8fIedqNiIMrHp6kKpYP49OWprhOFB/VaCPMND+yJylaJEWzJMkF/RRKnVFkOvudamRU9VGIbR69nXDXJdHrTy+rUhc4qvr7qrpdVXcB7wS+Pd0wW6qjIUbOqmX2cYRc1x66pAs/mDrSLfnDnHIPTLyfTGCyHHIOcLa4iXN6dCI7d67cRzEYpRwsPkFrrtzHwXS48SVfjgect6woqt59aTf5WOpJQxhnCDg99jCn+Q6VcvgFZpih/Eh0NPUz1RLd2SfoPi8BAvygH79GXgc/6Ods9vGK9VtWLrPtvow+t4/ei0BVHyGMC2NZAA3i1oDzOfxm+g1oFZ8t5e9nqa9vWSaq2n1psdSb5c4h2AtkIbYvZKWxnoXdw05V3VBrZWCibU9GhwvVr5GY7z1UbNso4t+XVfXq6PjDQP+kCcF2Vf3gXBef1L4XQttWy/i9Ltn3FmLf3Ur114vlqr/yd3c5jTOAiDy10mNBNPo9NLp+1VCLe5i8+xLoJtx9+R/A54GLiHZfqupMEWeXRK+VQr3vdbXX3yA+Z4ul9tjdl5aVTAP5nC0Wi8UyTj2Mc4X8RyuORr+HRtevGhr1HhpVr6Wg3ve6qutfdp+zxWKxWObGujUsFoulAbHG2WKxWBqQZTXOIvIWETksIseiNaYNj4jsEJGHReSgiBwQkfdH8oaLbrYS2xdWTvS4ldq+c1Hv9p+rXUUkJSKfiz5/okK2+sXUXfH3Pa3MrSIyLCL7or//Vav6Z0VVl+WPMEHfi8BuIAk8C+xdrvoXofcW4GXR+1bgCLAX+L/AXZH8LuDP66znimzfSPfXAi8Dnp8ks+27Ctq/mnYF3gf8XfT+ncDnalh/xd/3tDK3Em5kWtb/y3KOnF8BHFPV4xqGfvssYYSwhkZVz6rqM9H7UcLUO9tovOhmK7J9YcVEj1ux7TsXdW7/atp1si5fAN4QJZ5eNLP8vuvOoozzPB/ztgGnJx130iCNUC3R49QNwBPMI7rZMrHi23catn3ry3K1fzXtOlFGVX1gGIgHIV8k037f07lZRJ4Vka+KyFW1rrsSCzbOUXbdjwJvJXzMv0NE9tZKsUZDRFqALwIfUNWRyZ9p+OxT8zWJF6qPc74sRfvatq2epfp+NxKz/b6BZwjjX1wH/A1hCICl1ynyqcz/RJGbgT9S1TdHx78PoKp/Nkv5xyt9Nj8cQEg6GVokDUBWS/haxGg5CqDvknJa8dSlKHl8k5v7qpLGkxSeuiTFBaCAT5kiRn2mZ0dZIH1aZQCZqPM7AryRcDTxJHCHqh6coXxVyjVLe0xmKpza4iRism3rhmOyZ3uLc9a5zt0Yv1ZrPOv6geF4Psaw3atiydo2OmfJjNONN15cUf700y8tVZUL4YiqXl7riy7ULjQ58e/xXOy9Yc28yi9j+1f87i4mtkalx5FXTi8UD1juzrOaqa4lkRSOpNja/CpendhDYOBp/yS95iXy5QHKfh+uu4bLUq+nQ9s45BygO/sEsxtWIZPaRYe3m7WmnV3uWhyBY/4A3XKSXNDPWPFkDQx0UCny1kxM+OLC+5ZxX9yMBqSatr0ifVtMVpS4gX11ZnNMdvfPfTUm6/i743PW+aaWX4jJ/uwNP4zJrnygK65bOS6rzFK3Lcz/u1sdTzz5JxXlnvMrM5yx3IPYAOD+Jbr4k+HL/Nr28vTb5l3RE0++ZV7lPedd865jYVT+7i554CNdcMByIZ3cRrPXgdEAxaAaUDZ5jPoMBWd4HFACev1jlPxR1qZ3cVHi9Wx0WnndJmVTusgXT13Pl3kqls17mpbky310myJ+cjfbdA1rPIc3tnTQnlzLi2Mej7mnGGWAwfJJSuXBSEUH1GC0ALXPJzhn52czdSyYqgYWlincvRQXVVW/RnN7FxyLMc5ngB2TjrdHspoguKxJbGeLXowRQ4BP2Skx4HZRDEbIlrsZyh9islFs59Xc3LaOizJl3n75ITo293J09HV8OevMOdjwg0H8YJBhJ0XgXk5ChFs29XPtxS/y3Et7yL20g+7iJg4mAgZMEcFFxAldKX6xLg65hXd8lmqwnd95dH5hVd8CfIRwOPyPqrokhv1CZzHG+UngUhG5mNAovxP4xZpoFZGWFtaaZsYo0u324muRYjBCKcjiSIKktwERhyavnZTTQrO2cCZnKJkEz5y6mPW9G3lpTKIs29VRCrKcc0YoF1p4bmAtfnApL4y00VUsMigj5INBVH0yyU3skCspSYnjPE7Z763lrcMSd36rnKra1nZ+82fSQoEJf76IPDCbP99SmQUb5+hx5LeArxP2kPeo6oGaaSYeG4Mt7GpOcyyndBcOUg6GQH0UJZPaxS73etZqG1e1NLM+pTwzGPCN0lfRouFL2Q48STFcfmIOl8ZUiuVu9gcP4jhJnuxuJ9nXQikYI1fuQ9XHaB7VgEu4jXdtS5P1XT7aew2nx75ds1uPWJLO71Vt8Y1exQoemRvWFWKyavzLlfjc8Mfisi/Gyz30yp+JyU6OxCdxfu3QpxakxySWfGCxilmgP98ynUX5nFX1QeDBGukSIQgujqTwcHAFFMUPRlEtAC6C4DkpmrSJZkmwNql0pHwchHypC9US+dKpBdYfEJhhAsOso+EELutSRZKuR5tZh0g66jiq7whmY8k7v1VMvdr2+ubKsf+Xb+JpWVjgQgHLdBouE0rS28Se1M2kNE2/DPDNwhmGOYdqEZEkW5pfyUbdzogMcVz3Izh0Du0iYzKccA7NZ+nVojjIk/zjizeTdjwudTdyReuvsj84zZHsg9RqcnBpOj8L2LatN9ZlNDcNZ5ybE+u51tuC5wjfLp3i7Nj3Jj5zpJXd5lIuyzSxP+vxUuFhVAv086Nl13M4f5BHOEg6uZ13r7ud69fl0K7tHBUX1Zqv3LBYVgp2rqRGNJxxdiVBJiEkHfDKKQAS3ga2pq8jrRnKxud4tkCPexa0Ni6ExeCIx5qE0pHOk/GasVFYLasc68+vEQ1nnFPSwua0knINzdlWAC5OvYpf2bAVB/hM9xBPF/+TwORr5t9dDJ6k2NZcZPeGbjZ0tyO4Db3P9fK2+IaTHZmxmOxn9312OdSZwhufuC8mO3Tba+IFDy2DMpYFYedKakfDGWdHXEQUTxQnGoUmNEmrF2CAohTwg8H6KjkJxVA0DoViirLaxfQWi/Xn14aGM85lLTBSdigZoUi4nKtTD/GfZ25BgbPmhfoqOI1s6Ryf7BriG2d3ckgOR7sFLZY4+3L31lsFywqi4YxzQJmcD4EK5Sjmw1jxDE+lwyh+2dK5eqoXw5hR9uf+nf31VsRiWUUspKPznJXVOTaccfZNkZGykgwEX0PjbLRIzu+feG+xWCwXOg1nnEtmjLOlAgkccoS+ZdUChdJ43G+7TG0xfL0rHv3rwezyT/5Vy5Vf+d7chSyWC5CGM86qhoAAB5m2XtgaZYvFsnpouEW5Ig4ubrhJW5Ymfq7FYrE0Og1nnAEcBMfGeLVYLKuYhnNrlPxRXmp6CZcE+ULVIWQbApE0Sa8do2V8f7AhNslYLJaVScMZZz8YoHPsUSDMcrKSSCXWsyl5BSXN022eQ81oXfVZn7kxJnsw+/d10GTh/PaW98Vkf3k2HoLUYrnQaCDjLNHWZ12xI86E00SbWUdeUjjiUX2If4vFYpnKnD5nEblHRHpE5PlJsnYReUhEjkav8Qju88Rz22lO7STpbWCpEmkuNWu8bVyV3MDlsoOkN79MvxaLxTKZaiYEPwVMT1t7F/AtVb0U+FZ0vAgEz22iyVtLws0grMzJwGZtpSMlrE24eJKqtzoWi2UFM6dbQ1UfFZFd08S3A7dG7z8NPAL83mIUSToZ2tiIuoacjCdkDbOeKEo91zm7zhrWpncDMFQ4TmCGK5YrSYl8AIVACWoQzlRETgCjhDfvq+pNi76oxWJZESzU57xJVce37J0DNi1ODYe0u4Z200HglhmIBvQiCRxJYbRY1wD2meRmrtVwcu2p5BijhRmMs+YYLSvZIMDULiPL61S1byEnvj39qpjs89E2+Mn8ytrbYrKPdX90IVVWzdiHOmKylv8T160rv6RqWCwNy6LXOauqwswhjEXkThF5SkSemu06HimaSZHQFBL5nAUXEWfiGATXWUPS24zjtC5W9arJuOvZnUmxO5Oi2Y0blXF8ioz6AWOmjGmARAAWi2XlstCRc7eIbFHVsyKyBeiZqWA1ucIEYQ3r2ZRMUSx18JJ4oILjJPHcDD5gghwiKfam38Qup4PDeoaj2a8uy8qOK8yV3HnVMVSFo09eRTc/qFhupNzFC8l1lJwcfpCtRdUKfCNqt7+P2nICmyTTYrlwWejI+QFgPGXwu4D7F6tIQpNkPCFFYpLUwZUUImEf4kiKjaxlV4vLRrMBZHlWAq5LJLho1yku2nWKdV5yxnJ+kGfEnGMs6KlV9LxbVPVlwFuB3xSR107+UFU/oao3WV/0/BGREyKyX0T2zfVUZ6keEdkhIg+LyEEROSAi76+3TiuVapbS3Qt8H7hcRDpF5N3A3cAbReQo8BPR8cIRhzbN0JFS1riJCWOccDMTKzjAIeG1cutGl/9y2Yu8uj2N6zQtqtpqMQqqAkYwOnMSqsBkGS11UfCH8dxWPLcDkfSC61XVM9FrD3Af8IoFX8xSidep6vW2c6spPvA7qroXeBXhoGJvnXVakVSzWuOOGT56Qy0VaXESbEz79BQSOIUE4JB0W2iR9fhOkTxCym3jddtPc+MvPUTPx3+Oj/Q0LV/KKiMYM/v6a9UCZb+ASJKm5FaSTgvZcjdlf/7ZUUQkAziqOhq9fxPwx/O5xlVr4pOSmwtXxmQf+fAnYrKP/fJ8apo/GlS3lv2zQ/HdgH+y69djsj84sbQTmJbqiBYKnI3ej4rIIWAbcLCuiq1AGmaHYNEEjJUT5HyNtm0byiZH3hmmbPLhzkENKAcumhMCXb6YTdkgoLdnA8a4jAVz+7iFBGu9HbTSzlmvTNnvY5Y505nYBNwnYQAoD/iMqn5tvhexzMis/nzL4omW4N4APFFfTVYmjWGc1XDO6efIyBY6y2MYUwKUfKmLQqkXpQwEBOpzbqyN0cPb6c4113K52qy8JGd44MgVGIWTzsk5yye8NbzCuZptzQ7fHU3zHMeY7zptVT0OXLcwjS1VcIuqnhGRjcBDIvKCqj46uYCdcF04ItICfBH4gKqOVPjctu0cNETIUEUpUmDUD8hLEY2iUqiWMJpFtRSVC8j6HoXhVnKBi+ryRK/IMsSJMZdTWZcCYwges20xd8RjTcJhQzqgVZuXRUfL/KjGn28nXBeGiCQIDfO/qeqXKpWxbTs3DTFyFoQESZpcl1R55tUQ5SDLjwYyND97Hc8NJjGR0V5qBssneVK306QprpQruD6zl2N0zbiULzAleos+SddjSGKDhmXjuaFETHY8+9WY7A8/FI/8Bksb+W3vR6+Oyf7hip0x2Xte+GRM9sMFbck5Ty38+ZbKSOiH+yfgkKr+Zb31Wck0xMgZIKlJ0m64lE5mUCswBZ4dyfPNc2s4kBtBlynZa7F0joPFb3KYZ7i0JclPbS/zssQOZIbV1v4lrgAACjNJREFUIkaL9Joc5/IBI84g/3979xYbx1UGcPz/zc56Hcd2WtvUzb0t5IEWHiioohShiEoIharlAapyqSpUgSpAKvAAgQqQkECFBwQSQlWkoraAeuGi0nJ5gF5UBegltElbt6JNQpsmbeLETmzvxvbuznw8zDjaei9er3dmz9rfT7K8OzvJOfPZc+b4zJzvYPnpXDMK7BWRA8DTwF9sPL9trgJuBD4aP6a4X0R2dbpS3ciJnjNEeSnmAmWe0rlhjVp8BF+i1VJSu7aIj59Zh+/lyAhkRPEa5GYKtcyEdwoNlIJUT0k2nWXj+clR1b3QpZnLHONE46woBZliojTClHcG6owlCx59ns95PUof9Yc/2i3jraM/O8oQm8h5Sz91EYZ5XpvdyxHxCcICLTypYYxZ45xonAFKOsc8ZYpSrLsCiohH1vPIeUo2zrmRVrOXIUsGn4wX9ZwbpzVVwnDGBjOMMS1zpHEOmQ/zTHpnmNUp6o3RiviM9nq8cyDP4Xw/zHkVnVIhqR5qEBaYnD+E5kLO77mAdw2dYmyqD2/a7dVOHiuONbXfzk3Hq7b96Gitp1HalxnwjfyjVdu+8NLdVdu+6FXfEHw4f0fb6mGMq5y5IVgM8xRkirlwusGwRoahnLKpf4ahHBU3DhfGn5MZ6lItUiqfZKZ0nAE/YOPISYZ6AhwKnzFmlXGmdSkFBWaCceaD6Ti5frVQS5ycE/43vYGTc7roxmFI0mO7vpfj4sEpNr33Vbatn8WT6kfVjDGmHRwZ1lBK5Ummy6cbrnoShnM8X5imUB7gpeJExaN06Yw85zKDXH7ZGOWvf44PPPcs/sFeipa22RiTAGd6zhDGDXP9UVwlYMo7w8liibxME1U/vcVgPTL4PSW8dRvJZtOZOm6MWZsc6TkLPf4ofdkR5oNpZovHqNV7Vi1xpPQc45nzUA0ZyG0n0DJni8dQXX7mt+WaC6YYG3s3V935XV54/dME4dHEy1yJPm1utZiPPV09w/bGoa9Ubfv1ZLKZ3976rE0oM2aBMz3nXn8DQ95W1mffgUi93nDAXPEoZ2ZfZLY0yaC/kUH/QryUVrou6zwHTw9z4p/v4fD0IEGYzgxFY8za40jPOeIt41rhZ3oZCkcJKDPhHaq7InY7Fcsz/PtUH8Fz7+eZCT+13B7GmLVnycZZRLYC9xDlI1Bgj6r+XESGgPuBi4DXgOtVteXM9/V7y7X1+xdwiTdEMQw54g9QLFc/q9tu5WCSe07fx73T6ykFM4RhPvEyjTFrUzNd1XrLzuwGHlHVHcAj8fuWqQaEhE2nAQ20REmVkiphSqlDQSkHE8wWj8QrsKz8KRER+ZWIjIvIixXbhkTk7yLyavz9/BUXZIzpKs0sU1Vv2ZnrgJ3xbncDjwPfarUipXCWfGaCYpivOwml0pm5w+zNzaMaMFtMvtecoLuAXxD9dbJg4cJ3u4jsjt8vO7abw9Gqba80+W+TvvlXy9b7DqRepjGuWtaY86JlZ0bjhhvgONGwR61/09SKB0FYpBiepRzO152E8vb9p5iaTX6cOWmq+kQc10ptvfAZY7pP03fgGi07o6pKnb/xm13xoNffwHmZzfT5w8sef16FmrrwGWNWr6Ya5zrLzpwQkY3x5xuB8ZVUoz9zAduCLZwvmxBsWvSCRhc+EfmSiOwTkX0pV8sYk7AlG+cGy848BNwUv74J+NNKKtIjffR5PutszT1o8sJn67AZs3o1M+a8sOzMCyKyP972HeB24AERuRl4Hbi+1UoIwlAwzOb1PvOFDXheD2FQaPW/Ww0WLny3s4IL35XD1QsSPObwpMbR9R+s2nai8GQHamJWSqKxyX3AMVW9ptP16UbNPK3RaNmZq9tSC/FYR46BLPRlfByauJg4EbmX6ObfiIgcBb5PGy98xnTIrcDLwGCnK9KtnJkhKAgZUXxxefkxwfP6yXi9BMFZQl15715VP1Pno/Zc+IxJmYhsAT4B/BD4Roer07Wc6aJ6CFnP9ZUhPXqzw2zIbSOXHcb12hrTIT8DvkmDFJN2M3tpDjXOS69q7YJQy5TDeUK1RM6us9mX6RORa4BxVf1Po/3sZvbSnBnWyEqGHk/p8TxEnLlmLBIwXxqnWDodJ/p3e1Xt9X771vxLQwI3/+4iodmXpq6rgGtFZBfQCwyKyG9U9fMdrlfXcbUVdJZqkVALKNZzdp2qPgFMLtp8HdGsS+Lvn0y1Uqucqn5bVbeo6kXADcCj1jC3xomes2rAmLzM7PgOjnsnCIKzna6SWb2ann3ZbOoBY5LgROMMAW8W9vIm/yKNhVqNgWj2pYjU/WVT1T3AHoBG+5naVPVxorwwpgUODWssLOxq54BJVBvTDhiTnLR7zqcgKETfu9oIrR3D9nZXpMIpCF6PX48Ap2577ZcJFpe45ca42di2OvtyIb6t/uy70cKxJvl7C2//3a1VfqekVX7N+EqUVyc9IrKv2x+fcf0YXK9fM9pxDJWzL4ETRLMvHwQeALYRz75U1cU3DROtV7fo9LGu9fIdGXM2pv1s9qXpZg6NORtjjFnQicZ5TwfKbDfXj8H1+jXD1WNwtV5J6PSxrunyUx9zNsYYszQb1jDGGAel2jiLyMdF5L8icjDOa+A8EdkqIo+JyEsiMiYit8bbnUug043xhe5JUNSt8V1Kp+O/VFxFJCci98efP1VjQeSVlF3z/F60z04RmRKR/fHX99pVfkOqmsoXkAEOAZcAPcAB4NK0yl9BvTcCl8evB4BXgEuBnwC74+27gR93uJ5dGd+47h8BLgderNhm8V0D8W8mrsCXgTvi1zcA97ex/Jrn96J9dgJ/TvvnkmbP+QrgoKoeVtUicB9REhqnqepbqvps/HqGaHWHzbiXQKcr4wtdk6Coa+O7lA7Hv5m4Vtbl98DV8dqmK9bg/O64NBvnzcAbFe+P4kgQmhX/OfU+4CmWkUAnJV0f30Usvp2VVvybieu5fVS1DEwBw+2uyKLze7ErReSAiPxNRC5rd9m12CSUJolIP/AH4GuqOl154VZtnEDHrIzFt7PWQvwXn9+LPn4W2K6q+ThP9YPAjqTrlGbP+RiwteL9lnib80QkS/SD+62q/jHe7FoCna6Nbx0W385KK/7NxPXcPiLiAxuAiXZVoM75fY6qTqtqPn79VyArIiPtKr+eNBvnZ4AdInKxiPQQDew/lGL5LYnHtu4EXlbVn1Z8tJBAB5aXQCcpXRnfBiy+nZVW/JuJa2VdPkWUwL8tPfkG53flPhcujHGLyBVE7WbbLg51pXn3EdhFdDf0EHBb2nc/W6zzh4nymD4P7I+/dhGNeT0CvAr8AxhyoK5dF9+43vcCbwElojHHmy2+ayf+teIK/AC4Nn7dC/wOOAg8DVzSxrLrnd+3ALfE+3wVGCN6kuRJ4ENp/FxshqAxxjjIZggaY4yDrHE2xhgHWeNsjDEOssbZGGMcZI2zMcY4yBpnY4xxkDXOxhjjIGucjTHGQf8HXoi6T+Jf4BgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAoiddK7C7fH"
      },
      "source": [
        "Let's change the 64 filters with other value n see the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y4a5VGBDEFz",
        "outputId": "3174f9b6-b59c-464d-fba9-a1e602353b97"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')      \n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               102528    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 113,386\n",
            "Trainable params: 113,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4710 - accuracy: 0.8313\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3202 - accuracy: 0.8832\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2751 - accuracy: 0.8986\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2477 - accuracy: 0.9084\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2203 - accuracy: 0.9181\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2549 - accuracy: 0.9076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpA63V0sDOEp",
        "outputId": "6fd87919-fdbd-42c7-eb4c-2f4f7be7343d"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')      \n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 11, 11, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 55,098\n",
            "Trainable params: 55,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5161 - accuracy: 0.8123\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3564 - accuracy: 0.8705\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3106 - accuracy: 0.8861\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2838 - accuracy: 0.8948\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2618 - accuracy: 0.9027\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2894 - accuracy: 0.8980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQPwmJWiDSqx"
      },
      "source": [
        "The impact of changing 64 filters of convolution into 32 and 16 is that it reduced the accuracy slightly. The training time also decreased but just insignificantly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crK2VfJZEKaU"
      },
      "source": [
        "What happens if we remove the final convolution?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJG7yozzEaU2",
        "outputId": "99ff76fe-057f-43a4-8d6d-f03ae45b6162"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')      \n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10816)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               1384576   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,386,506\n",
            "Trainable params: 1,386,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3770 - accuracy: 0.8660\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2520 - accuracy: 0.9094\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2068 - accuracy: 0.9232\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1731 - accuracy: 0.9363\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1444 - accuracy: 0.9470\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2561 - accuracy: 0.9140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIhQUMglE_3O"
      },
      "source": [
        "The accuracy increased insignificantly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i8cQqSPFPil"
      },
      "source": [
        "What happens if we add 1 more convolutional layer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhKQ2Kh_FEhC",
        "outputId": "3edb01f9-6f1e-4796-cef2-e788235f10d4"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')      \n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 84,106\n",
            "Trainable params: 84,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5681 - accuracy: 0.7915\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3856 - accuracy: 0.8564\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3282 - accuracy: 0.8772\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2930 - accuracy: 0.8896\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2684 - accuracy: 0.8998\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3127 - accuracy: 0.8865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ckNPtytFVUX"
      },
      "source": [
        "The training time increased and the accuracy has reduced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hlr1mXgzFedX"
      },
      "source": [
        "What happens if we remove all the convolutions but the first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Surtym-iFiP8",
        "outputId": "b2c0123c-8032-4fcc-8a47-2c19d33326d9"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')      \n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               73856     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 75,786\n",
            "Trainable params: 75,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5756 - accuracy: 0.7943\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4062 - accuracy: 0.8523\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3616 - accuracy: 0.8672\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3345 - accuracy: 0.8768\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3141 - accuracy: 0.8828\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3448 - accuracy: 0.8748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBaH_ErtF_dc"
      },
      "source": [
        "Let's try to implement the callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0lorloaGSLO",
        "outputId": "b9344f72-28f1-4567-915c-5d8fc2800129"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.9):\n",
        "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')      \n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=15, callbacks=[callbacks])\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4482 - accuracy: 0.8361\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2967 - accuracy: 0.8916\n",
            "Epoch 3/15\n",
            "1859/1875 [============================>.] - ETA: 0s - loss: 0.2492 - accuracy: 0.9080\n",
            "Reached 90% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2494 - accuracy: 0.9079\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.8963\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}